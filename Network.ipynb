{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NYBOPHMqiYOo",
        "outputId": "6d480c67-dd19-4654-aa6e-2da2845caf73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (70.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting mxnet<2.0.0\n",
            "  Using cached mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet<2.0.0) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet<2.0.0) (2.31.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet<2.0.0)\n",
            "  Using cached graphviz-0.8.4-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2024.7.4)\n",
            "Using cached mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "Using cached graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.3\n",
            "    Uninstalling graphviz-0.20.3:\n",
            "      Successfully uninstalled graphviz-0.20.3\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting autogluon\n",
            "  Using cached autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\n",
            "  Using cached autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.features==1.1.1 (from autogluon)\n",
            "  Using cached autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Using cached autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.multimodal==1.1.1 (from autogluon)\n",
            "  Using cached autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Using cached autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.25.2)\n",
            "Requirement already satisfied: scipy<1.13,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.11.4)\n",
            "Collecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Using cached scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Using cached boto3-1.34.144-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Using cached autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Using cached ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.1->autogluon) (0.2.7)\n",
            "Collecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Using cached pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: torch<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (2.3.0+cu121)\n",
            "Collecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Using cached lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Using cached transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
            "Collecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jsonschema<4.22,>=4.18 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (4.19.2)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: torchvision<0.19.0,>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (0.18.0+cu121)\n",
            "Requirement already satisfied: scikit-image<0.21.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (0.19.3)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (3.8.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (2.15.2)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: xgboost<2.1,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.0.3)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.15)\n",
            "Requirement already satisfied: lightgbm<4.4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.1.1->autogluon) (4.1.0)\n",
            "Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\n",
            "Collecting pytorch-lightning<2.4,>=2.2 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting orjson~=3.9 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (70.3.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.8.2)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.12.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.1)\n",
            "Collecting botocore<1.35.0,>=1.34.144 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading botocore-1.34.144-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.8.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.23.4)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.50)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.7.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.19.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading lightning_utilities-0.11.3.post0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.58.1)\n",
            "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (5.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2024.5.15)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.7.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.9.0)\n",
            "Collecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.13.0)\n",
            "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.1 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.15.4)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.8)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.4.1)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (14.0.2)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.9.5)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.20.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (7.0.4)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading virtualenv-20.26.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.64.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.7.4)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (1.6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.1.99)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.3)\n",
            "Collecting pyarrow>=6.0.1 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.6)\n",
            "Collecting requests (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.3.1)\n",
            "Collecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.41.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (24.3.25)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.20.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.12.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.16.2)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (8.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.14.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.63.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.18.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.5)\n",
            "Collecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\n",
            "Downloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\n",
            "Downloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.0/428.0 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.34.144-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.3.3-py3-none-any.whl (808 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m802.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\n",
            "Downloading botocore-1.34.144-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.11.3.post0-py3-none-any.whl (26 kB)\n",
            "Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.26.3-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=d71a5c3415d0e19a760023075245c0822154e816b896d7988464678f130efccc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144551 sha256=58b0df8caee30aa79e0d0214c6a1a66984f2fe58d3c0c0971693ff8b6b0dba6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16160 sha256=7f96508de3c7942d2351df2b2ea7631bf00d5ab8edbe5f923646c5a3753e18e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, antlr4-python3-runtime, xxhash, virtualenv, tensorboardX, requests, pycryptodome, pyarrow, Pillow, orjson, ordered-set, openxlab, onnx, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, lightning-utilities, jmespath, humanfriendly, dill, colorama, window-ops, scikit-learn, pytesseract, pdf2image, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, model-index, coloredlogs, botocore, utilsforecast, tokenizers, seqeval, s3transfer, opendatalab, onnxruntime, nvidia-cusolver-cu12, gluonts, catboost, aiohttp-cors, transformers, statsforecast, ray, openmim, opencensus, nlpaug, mlforecast, datasets, boto3, torchmetrics, pytorch-metric-learning, evaluate, autogluon.common, accelerate, timm, pytorch-lightning, optimum, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.0.1 accelerate-0.21.0 aiohttp-cors-0.7.0 antlr4-python3-runtime-4.9.3 autogluon-1.1.1 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.multimodal-1.1.1 autogluon.tabular-1.1.1 autogluon.timeseries-1.1.1 boto3-1.34.144 botocore-1.34.144 catboost-1.2.5 colorama-0.4.6 coloredlogs-15.0.1 colorful-0.5.6 datasets-2.20.0 dill-0.3.8 distlib-0.3.8 evaluate-0.4.2 gluonts-0.15.1 humanfriendly-10.0 jmespath-1.0.1 lightning-2.3.3 lightning-utilities-0.11.3.post0 mlforecast-0.10.0 model-index-0.1.11 multiprocess-0.70.16 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnx-1.16.1 onnxruntime-1.18.1 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 ordered-set-4.1.0 orjson-3.10.6 pdf2image-1.17.0 py-spy-0.3.14 pyarrow-16.1.0 pycryptodome-3.20.0 pytesseract-0.3.10 pytorch-lightning-2.3.3 pytorch-metric-learning-2.3.0 ray-2.10.0 requests-2.32.3 s3transfer-0.10.2 scikit-learn-1.4.0 seqeval-1.2.2 statsforecast-1.4.0 tensorboardX-2.6.2.2 timm-0.9.16 tokenizers-0.15.2 torchmetrics-1.2.1 transformers-4.39.3 utilsforecast-0.0.10 virtualenv-20.26.3 window-ops-0.0.15 xxhash-3.4.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              },
              "id": "c5b38ad136124fbd9e0a26401675abb5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade setuptools\n",
        "!pip install --upgrade \"mxnet<2.0.0\"\n",
        "!pip install autogluon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor, FeatureMetadata\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "zmiLPZOSk8rk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor, FeatureMetadata\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "hbcmzH3JmNzB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run from here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zCQlTRT_mW0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Total number of rows in the dataset\n",
        "total_rows = 21000\n",
        "\n",
        "# Sample data to represent your specified columns\n",
        "data = {\n",
        "    'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.80.hist.bins._64_127.count': np.random.randint(0, 100, total_rows),\n",
        "    'smf.smf.app.cadvisor.container_memory_rss': np.random.uniform(0, 16*1024**3, total_rows),  # up to 16 GB in bytes\n",
        "    'ausf.ausf.app.cadvisor.container_memory_rss': np.random.uniform(0, 16*1024**3, total_rows),\n",
        "    'amf.amf.app.cadvisor.container_memory_rss': np.random.uniform(0, 16*1024**3, total_rows),\n",
        "    'upf.upf3.app.cadvisor.container_memory_rss': np.random.uniform(0, 16*1024**3, total_rows),\n",
        "    'amf.amf.infra.tcpwin._192.168.13.80_192.168.13.82.snd_cwnd.hist.bins._4_7.count': np.random.randint(0, 100, total_rows),\n",
        "    'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.80.stat.avg': np.random.uniform(0, 500, total_rows),  # RTT in ms\n",
        "    'udm.udm.app.cadvisor.container_memory_rss': np.random.uniform(0, 16*1024**3, total_rows),\n",
        "    'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.82.stat.avg': np.random.uniform(0, 500, total_rows),\n",
        "    'udm.udm.app.cadvisor.container_memory_rss': np.random.uniform(0, 16*1024**3, total_rows),\n",
        "    'upf.upf3.app.cadvisor.container_memory_rss': np.random.uniform(0, 16*1024**3, total_rows),\n",
        "    'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.82.stat.avg': np.random.randint(0, 100, total_rows)  # RTT in ms\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define thresholds for each attribute based on their average range\n",
        "thresholds = {\n",
        "    'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.80.hist.bins._64_127.count': 50,\n",
        "    'smf.smf.app.cadvisor.container_memory_rss': 8*1024**3,  # Half of 16 GB in bytes\n",
        "    'ausf.ausf.app.cadvisor.container_memory_rss': 8*1024**3,\n",
        "    'amf.amf.app.cadvisor.container_memory_rss': 8*1024**3,\n",
        "    'upf.upf3.app.cadvisor.container_memory_rss': 8*1024**3,\n",
        "    'amf.amf.infra.tcpwin._192.168.13.80_192.168.13.82.snd_cwnd.hist.bins._4_7.count': 50,\n",
        "    'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.80.stat.avg': 250,  # Half of 500 ms\n",
        "    'udm.udm.app.cadvisor.container_memory_rss': 8*1024**3,\n",
        "    'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.82.stat.avg': 50,\n",
        "}\n",
        "\n",
        "# Assign labels based on threshold crossing\n",
        "conditions = []\n",
        "for col, threshold in thresholds.items():\n",
        "    conditions.append(df[col] > threshold)\n",
        "\n",
        "# Count number of conditions met for each row\n",
        "num_conditions_met = np.sum(conditions, axis=0)\n",
        "\n",
        "# Assign label based on number of conditions met\n",
        "df['label'] = (num_conditions_met >= 5).astype(int)\n",
        "\n",
        "# Set 'amf.amf.app.five-g.RM.RegInitFail' based on num_conditions_met\n",
        "'''\n",
        "df['amf.amf.app.five-g.RM.RegInitFail'] = np.where(\n",
        "    num_conditions_met < 5,\n",
        "    0,\n",
        "    10 - np.clip(num_conditions_met, 0, 10)\n",
        ")\n",
        "'''\n",
        "# Save to CSV\n",
        "df.to_csv('/generated_dataset.csv', index=False)\n",
        "print(\"Dataset generated with labels and saved as 'generated_dataset_with_labels.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ls956-OnQUp",
        "outputId": "c93e7a56-c5ce-4fed-ea1f-3265c540846f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset generated with labels and saved as 'generated_dataset_with_labels.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/generated_dataset.csv')\n"
      ],
      "metadata": {
        "id": "qNpb3qZyurSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df))\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVaX-yhpu48F",
        "outputId": "55dbeeaf-ea70-4bc7-87db-ffc50bfc6b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21000\n",
            "Index(['udm.udm.infra.tcprtt._192.168.13.70_192.168.13.80.hist.bins._64_127.count',\n",
            "       'smf.smf.app.cadvisor.container_memory_rss',\n",
            "       'ausf.ausf.app.cadvisor.container_memory_rss',\n",
            "       'amf.amf.app.cadvisor.container_memory_rss',\n",
            "       'upf.upf3.app.cadvisor.container_memory_rss',\n",
            "       'amf.amf.infra.tcpwin._192.168.13.80_192.168.13.82.snd_cwnd.hist.bins._4_7.count',\n",
            "       'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.80.stat.avg',\n",
            "       'udm.udm.app.cadvisor.container_memory_rss',\n",
            "       'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.82.stat.avg', 'label',\n",
            "       'amf.amf.app.five-g.RM.RegInitFail'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqBx_p7mtv-m",
        "outputId": "4b685c08-eac1-4324-9b37-b81f06d355ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the generated dataset\n",
        "data_raw_tab = pd.read_csv('/generated_dataset.csv')\n",
        "num_cycles = 300\n",
        "rows_per_cycle = 70\n",
        "# Identify cycles with failures\n",
        "cycleLable_train_arr = []\n",
        "for i in range(num_cycles):\n",
        "    dt1_train = data_raw_tab['label'][rows_per_cycle*i:rows_per_cycle*(i+1)]\n",
        "    if dt1_train.iloc[0] != 0:\n",
        "        cycleLable_train_arr.append(i)\n",
        "\n",
        "# Downsample and create final training dataset\n",
        "ind_train_60 = []\n",
        "data_train_1to12_12_tab = pd.DataFrame()\n",
        "\n",
        "for i_cycle in range(num_cycles):\n",
        "    if i_cycle in cycleLable_train_arr:\n",
        "        tmp = data_raw_tab.iloc[i_cycle*rows_per_cycle+10:i_cycle*rows_per_cycle+16, 2:-2]  # Skip timestamp and label\n",
        "        data_train_1to12_12_tab = pd.concat([data_train_1to12_12_tab, tmp])\n",
        "        for i in range(6):\n",
        "            ind_train_60.append(i_cycle*rows_per_cycle+59)\n",
        "    else:\n",
        "        for offset in [0, 10, 20, 30, 40, 50]:\n",
        "            tmp = data_raw_tab.iloc[i_cycle*rows_per_cycle+offset:i_cycle*rows_per_cycle+offset+1, 2:-2]\n",
        "            data_train_1to12_12_tab = pd.concat([data_train_1to12_12_tab, tmp])\n",
        "        for i in range(6):\n",
        "            ind_train_60.append(i_cycle*rows_per_cycle+59)\n",
        "\n",
        "data_failure_60 = data_raw_tab.iloc[ind_train_60, :]['amf.amf.app.five-g.RM.RegInitFail']\n",
        "data_train_12_mean_failure_60_tab = data_train_1to12_12_tab\n",
        "data_train_12_mean_failure_60_tab['fail60'] = data_failure_60.to_numpy()\n",
        "data_train_12_mean_failure_60_noTimeLable_tab = data_train_12_mean_failure_60_tab.reset_index(drop=True)\n",
        "\n",
        "# Save the final training dataset to CSV\n",
        "data_train_12_mean_failure_60_noTimeLable_tab.to_csv('/final_training_dataset.csv', index=False)\n",
        "print(\"Final training dataset generated and saved as 'final_training_dataset.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "7bFC_a4aoUYA",
        "outputId": "f1a4dee7-c2dd-4a51-f9de-5b950406df60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'amf.amf.app.five-g.RM.RegInitFail'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'amf.amf.app.five-g.RM.RegInitFail'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ba352c9aaf74>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mind_train_60\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_cycle\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrows_per_cycle\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m59\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdata_failure_60\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_raw_tab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind_train_60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amf.amf.app.five-g.RM.RegInitFail'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mdata_train_12_mean_failure_60_tab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_train_1to12_12_tab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdata_train_12_mean_failure_60_tab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fail60'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_failure_60\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'amf.amf.app.five-g.RM.RegInitFail'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "dir_default = \"drive/My Drive/model\"\n",
        "#dir_default = f\"{dir_base_name}_1025_train_12_failure_60_reg_cpu_4h\"\n",
        "data_input_tab = pd.read_csv('/content/final_training_dataset.csv')\n",
        "\n",
        "predictor = TabularPredictor(\n",
        "    label='fail60',\n",
        "    problem_type='regression',\n",
        "    path=dir_default,\n",
        "    verbosity=2,\n",
        ").fit(\n",
        "    train_data=data_input_tab,\n",
        "    presets=\"good_quality\",\n",
        "    ag_args_fit={\"num_gpus\": 0},\n",
        "     time_limit=14400\n",
        ")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o-jQxUtqRUI",
        "outputId": "b988d2db-b3be-48c9-bb27-8f12e3e56956"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"drive/My Drive/model\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.88 GB / 12.67 GB (77.9%)\n",
            "Disk Space Avail:   74.25 GB / 107.72 GB (68.9%)\n",
            "===================================================\n",
            "Presets specified: ['good_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
            "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 3600s of the 14400s of remaining time (25%).\n",
            "\t\tContext path: \"drive/My Drive/model/ds_sub_fit/sub_fit_ho\"\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                         model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    ExtraTreesMSE_BAG_L2_FULL      -2.314981  -2.264657  root_mean_squared_error        0.357002       0.536677  5.323882                 0.111450                0.158749           1.055008            2       True          5\n",
            "1     WeightedEnsemble_L3_FULL      -2.327163  -2.255574  root_mean_squared_error        0.468143            NaN  9.816380                 0.003680                     NaN           0.014602            3       True          6\n",
            "2  RandomForestMSE_BAG_L2_FULL      -2.339074  -2.259198  root_mean_squared_error        0.353012       0.545399  8.746770                 0.107460                0.167471           4.477897            2       True          4\n",
            "3     WeightedEnsemble_L2_FULL      -2.348971  -2.332453  root_mean_squared_error        0.248907            NaN  4.286812                 0.003355                     NaN           0.017938            2       True          3\n",
            "4    ExtraTreesMSE_BAG_L1_FULL      -2.350093  -2.335332  root_mean_squared_error        0.140397       0.227047  1.472611                 0.140397                0.227047           1.472611            1       True          2\n",
            "5  RandomForestMSE_BAG_L1_FULL      -2.355808  -2.341874  root_mean_squared_error        0.105155       0.150881  2.796263                 0.105155                0.150881           2.796263            1       True          1\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t22s\t = DyStack   runtime |\t14378s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 14378s\n",
            "AutoGluon will save models to \"drive/My Drive/model\"\n",
            "Train Data Rows:    1800\n",
            "Train Data Columns: 7\n",
            "Label Column:       fail60\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9734.28 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.10 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 5 | ['ausf.ausf.app.cadvisor.container_memory_rss', 'amf.amf.app.cadvisor.container_memory_rss', 'upf.upf3.app.cadvisor.container_memory_rss', 'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.80.stat.avg', 'udm.udm.app.cadvisor.container_memory_rss']\n",
            "\t\t('int', [])   : 2 | ['amf.amf.infra.tcpwin._192.168.13.80_192.168.13.82.snd_cwnd.hist.bins._4_7.count', 'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.82.stat.avg']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 5 | ['ausf.ausf.app.cadvisor.container_memory_rss', 'amf.amf.app.cadvisor.container_memory_rss', 'upf.upf3.app.cadvisor.container_memory_rss', 'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.80.stat.avg', 'udm.udm.app.cadvisor.container_memory_rss']\n",
            "\t\t('int', [])   : 2 | ['amf.amf.infra.tcpwin._192.168.13.80_192.168.13.82.snd_cwnd.hist.bins._4_7.count', 'udm.udm.infra.tcprtt._192.168.13.70_192.168.13.82.stat.avg']\n",
            "\t0.1s = Fit runtime\n",
            "\t7 features in original data used to generate 7 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.10 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.18s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 9 L1 models ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 9583.13s of the 14378.29s of remaining time.\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 9582.61s of the 14377.76s of remaining time.\n",
            "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 9582.14s of the 14377.29s of remaining time.\n",
            "\t-2.3429\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.91s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 9577.93s of the 14373.09s of remaining time.\n",
            "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 9577.51s of the 14372.67s of remaining time.\n",
            "\t-2.341\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.87s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 9575.3s of the 14370.46s of remaining time.\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 9574.97s of the 14370.12s of remaining time.\n",
            "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 9574.69s of the 14369.85s of remaining time.\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 9574.41s of the 14369.56s of remaining time.\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 958.31s of the 14369.24s of remaining time.\n",
            "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L1': 0.545, 'RandomForestMSE_BAG_L1': 0.455}\n",
            "\t-2.3361\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 9 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 14369.19s of the 14369.17s of remaining time.\n",
            "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 14368.83s of the 14368.81s of remaining time.\n",
            "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 14368.54s of the 14368.53s of remaining time.\n",
            "\t-2.2627\t = Validation score   (-root_mean_squared_error)\n",
            "\t3.85s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 14364.47s of the 14364.46s of remaining time.\n",
            "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 14364.12s of the 14364.1s of remaining time.\n",
            "\t-2.2659\t = Validation score   (-root_mean_squared_error)\n",
            "\t1.22s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 14362.64s of the 14362.63s of remaining time.\n",
            "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 14362.3s of the 14362.28s of remaining time.\n",
            "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 14361.93s of the 14361.91s of remaining time.\n",
            "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 14361.59s of the 14361.58s of remaining time.\n",
            "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training... Skipping this model.\n",
            "\t\tThe model requires minimum cpu 1, but you only specified 0\n",
            "Detailed Traceback:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
            "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
            "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
            "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
            "    self._fit_folds(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 690, in _fit_folds\n",
            "    fold_fitting_strategy: FoldFittingStrategy = fold_fitting_strategy_cls(**fold_fitting_strategy_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 486, in __init__\n",
            "    self.resources, self.resources_model, self.batches, self.num_parallel_jobs = self._get_resource_suggestions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 786, in _get_resource_suggestions\n",
            "    resources_info = resources_calculator.get_resources_per_job(**get_resources_per_job_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/ray/resources_calculator.py\", line 56, in get_resources_per_job\n",
            "    assert cpu_per_job >= minimum_cpu_per_job, f\"The model requires minimum cpu {minimum_cpu_per_job}, but you only specified {cpu_per_job}\"\n",
            "AssertionError: The model requires minimum cpu 1, but you only specified 0\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 1436.92s of the 14361.27s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L2': 0.556, 'ExtraTreesMSE_BAG_L2': 0.444}\n",
            "\t-2.2571\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 17.26s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 2311.2 rows/s (1800 batch size)\n",
            "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t3.91s\t = Training   runtime\n",
            "\t0.22s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.87s\t = Training   runtime\n",
            "\t0.23s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'ExtraTreesMSE_BAG_L1': 0.545, 'RandomForestMSE_BAG_L1': 0.455}\n",
            "\t0.02s\t = Training   runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t3.85s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t1.22s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L2': 0.556, 'ExtraTreesMSE_BAG_L2': 0.444}\n",
            "\t0.02s\t = Training   runtime\n",
            "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 0.44s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"drive/My Drive/model\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 22.8 s, sys: 515 ms, total: 23.3 s\n",
            "Wall time: 39.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_table = pd.read_csv('drive/My Drive/ML5G-PS-005_train.csv') #raw data\n",
        "data_test_table = pd.read_csv('drive/My Drive/ML5G-PS-005_test.csv') #raw data"
      ],
      "metadata": {
        "id": "tE6iiRb3lDS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_failure = []\n",
        "data_train_normal = []\n",
        "for i in range(0,600):\n",
        "  dt1_train = data_train_table['label'][70*i:70*(i+1)]\n",
        "  if dt1_train[70*i] != 'normal':\n",
        "    data_train_failure.append(i)\n",
        "  else:\n",
        "    data_train_normal.append(i)"
      ],
      "metadata": {
        "id": "g3lr3Y5_lOad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train data + test data\n",
        "fulldata = pd.concat([data_train_table, data_test_table])"
      ],
      "metadata": {
        "id": "92uwh_yBlTQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dt = fulldata.copy() #LSTMで用いるデータ\n",
        "#delete time, label columns\n",
        "del dt['time']\n",
        "del dt['label']"
      ],
      "metadata": {
        "id": "YLc6euMnla0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_udm = dt.iloc[:, 2391:2477]"
      ],
      "metadata": {
        "id": "7tef9R-0llZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feature_importance = ['amf.amf.app.cadvisor.container_memory_rss',\n",
        "'ausf.ausf.app.cadvisor.container_memory_rss',\n",
        "'igw.igw1.app.cadvisor.container_memory_rss',\n",
        "'igw.igw2.app.cadvisor.container_memory_rss',\n",
        "'nrf.nrf.app.cadvisor.container_memory_rss',\n",
        "'smf.smf.app.cadvisor.container_memory_rss',\n",
        "'udm.udm.app.cadvisor.container_memory_rss',\n",
        "'upf.upf1.app.cadvisor.container_memory_rss',\n",
        "'upf.upf2.app.cadvisor.container_memory_rss',\n",
        "'upf.upf3.app.cadvisor.container_memory_rss']"
      ],
      "metadata": {
        "id": "pqH-t29jm2bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dt_importantcolumn = pd.DataFrame()\n",
        "dt_importantcolumn = pd.concat([dt_importantcolumn, dt_udm])"
      ],
      "metadata": {
        "id": "zkMz5SM-m92s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i_column in feature_importance:\n",
        "  dt_importantcolumn[i_column] = dt[i_column][:]"
      ],
      "metadata": {
        "id": "5XIofhgHnATa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_importantcolumn.insert(0, 'amf.amf.app.five-g.RM.RegInitFail', dt['amf.amf.app.five-g.RM.RegInitFail'][:])\n",
        "\n"
      ],
      "metadata": {
        "id": "6-l9cUWLnH5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_importantcolumn.to_csv('drive/My Drive/dt_importantcolumn_feature_udm_rss_goodquality_1114.csv')\n"
      ],
      "metadata": {
        "id": "VLerp6aPnI_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read\n",
        "dt_importantcolumn = pd.read_csv('drive/My Drive/dt_importantcolumn_feature_udm_rss_goodquality_1114.csv')\n"
      ],
      "metadata": {
        "id": "4AYv4rBRnOZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "del dt_importantcolumn['Unnamed: 0']"
      ],
      "metadata": {
        "id": "l9S8BqBMnRC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dt_train_importantcolumn = dt_importantcolumn[:len(data_train_table)][:]\n",
        "dt_test_importantcolumn = dt_importantcolumn[len(data_train_table):][:]"
      ],
      "metadata": {
        "id": "1ir7mLqynUr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "data_train_normal_375 = data_train_normal[:375]\n",
        "data_train_normal_75 = data_train_normal[375:]\n",
        "data_train_failure_125 = data_train_failure[:125]\n",
        "data_train_failure_25 = data_train_failure[125:]"
      ],
      "metadata": {
        "id": "nEK0yIqcnuia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#separate train data(600 cycles) into 500 cycles and 100 cycles\n",
        "data_train_500_table = dt_train_importantcolumn\n",
        "data_train_100_table = pd.DataFrame()"
      ],
      "metadata": {
        "id": "1hnnG_Zgnyim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i_cycle in range(600):\n",
        "  if i_cycle in data_train_normal_75 or i_cycle in data_train_failure_25:\n",
        "    data_train_100_table = pd.concat([data_train_100_table, dt_train_importantcolumn.iloc[i_cycle*70:i_cycle*70+70, :]])\n",
        "    data_train_500_table = data_train_500_table.drop(range(i_cycle*70, i_cycle*70+70))"
      ],
      "metadata": {
        "id": "-8WjB_csn2A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_500_table.to_csv('drive/My Drive/data_train_500_table_1114.csv')\n",
        "data_train_100_table.to_csv('drive/My Drive/data_train_100_table_1114.csv')"
      ],
      "metadata": {
        "id": "jDMs5F8In48E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_500_table = pd.read_csv('drive/My Drive/data_train_500_table_1114.csv')\n",
        "data_train_100_table = pd.read_csv('drive/My Drive/data_train_100_table_1114.csv')"
      ],
      "metadata": {
        "id": "HlQU7gMNn7oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "del data_train_500_table['Unnamed: 0']\n",
        "del data_train_100_table['Unnamed: 0']"
      ],
      "metadata": {
        "id": "Fxf4PTbzn-Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_train_500_all = data_train_normal_375 + data_train_failure_125\n",
        "data_train_500_all.sort()"
      ],
      "metadata": {
        "id": "Ew-FOlUJoAqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training data\n",
        "ind_train_60 = []\n",
        "data_train_1to60_12_tab = pd.DataFrame()\n",
        "\n",
        "for i_cycle in data_train_500_all:\n",
        "  if i_cycle in data_train_failure_125:\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+10:i_cycle*70+22, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "    for i in range(12):\n",
        "      ind_train_60.append(i_cycle*70+59)\n",
        "\n",
        "  else:\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70:i_cycle*70+1, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+5:i_cycle*70+6, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+10:i_cycle*70+11, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+15:i_cycle*70+16, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+20:i_cycle*70+21, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+25:i_cycle*70+26, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+30:i_cycle*70+31, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+35:i_cycle*70+36, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+40:i_cycle*70+41, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+45:i_cycle*70+46, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+50:i_cycle*70+51, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    tmp = dt_train_importantcolumn.iloc[i_cycle*70+55:i_cycle*70+56, :]\n",
        "    data_train_1to60_12_tab = pd.concat([data_train_1to60_12_tab, tmp])\n",
        "\n",
        "    for i in range(12):\n",
        "      ind_train_60.append(i_cycle*70+59)\n",
        "\n",
        "data_failure_60 = dt_train_importantcolumn.iloc[ind_train_60, :]['amf.amf.app.five-g.RM.RegInitFail']\n",
        "data_train_12_mean_failure_60_tab=data_train_1to60_12_tab\n",
        "data_train_12_mean_failure_60_tab['fail60']=data_failure_60.to_numpy()\n",
        "data_train_12_mean_failure_60_noTimeLable_tab=data_train_12_mean_failure_60_tab.reset_index()\n",
        "\n",
        "print(data_failure_60.shape)\n",
        "data_train_12_mean_failure_60_noTimeLable_tab.head(6)\n"
      ],
      "metadata": {
        "id": "Y3qEcsJBoD-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del data_train_12_mean_failure_60_noTimeLable_tab['index'] #index"
      ],
      "metadata": {
        "id": "M1mXY4QBoKNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_12_mean_failure_60_noTimeLable_tab.to_csv('drive/My Drive/data_train_12_mean_fai"
      ],
      "metadata": {
        "id": "YLsnbM29oPvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_12_mean_failure_60_noTimeLable_tab = pd.read_csv('drive/My Drive/data_train_12_mean_failure_60_noTimeLable_tab_1116.csv')\n"
      ],
      "metadata": {
        "id": "vqFhg7jnoQ6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del data_train_12_mean_failure_60_noTimeLable_tab['Unnamed: 0']"
      ],
      "metadata": {
        "id": "WHI_k9FdoWm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_train_12_mean_failure_60_noTimeLable_tab"
      ],
      "metadata": {
        "id": "hupU5v-woZHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "dir_default = \"drive/My Drive/model\"\n",
        "#dir_default = f\"{dir_base_name}_1121_train_normal_cycle_96columns_good_noindex_reg_cpu_4h\"\n",
        "data_input_tab = data_train_12_mean_failure_60_noTimeLable_tab\n",
        "predictor = TabularPredictor(\n",
        "    label='fail60', # ターゲット\n",
        "    # label='amf.amf.app.five-g.RM.RegInitFail', # ターゲット\n",
        "    problem_type='regression',\n",
        "    path=dir_default, # モデルを保存するディレクトリ名\n",
        "    verbosity=2,\n",
        "    # eval_metric=\"f1\" ## 評価指標 Defaults to ‘accuracy’ for binary and multiclass classification and ‘root_mean_squared_error’ for regression\n",
        "#     eval_metric=\"roc_auc\" # 評価指標\n",
        "#     eval_metric=\"precision\" # 評価指標\n",
        ").fit(\n",
        "    train_data=data_input_tab, # トレーニングデータ\n",
        "    # presets=\"good_quality\", ## default = [‘medium_quality_faster_train’]\n",
        "    presets=\"good_quality\",\n",
        "#     presets=\"optimize_for_deployment\",\n",
        "#     presets=[\"good_quality\",\"optimize_for_deployment\"],\n",
        "    # excluded_model_types = ['CAT'],\n",
        "#     feature_metadata=feature_metadata,\n",
        "    # ag_args_ensemble={\"fold_fitting_strategy\": \"sequential_local\"},\n",
        "#    ag_args_fit={\"num_gpus\": 0},  # GPU の使用\n",
        "     time_limit=14400 # [seconds]\n",
        "#    time_limit=3600, # [seconds]\n",
        "#     hyperparameters=hyperparameters\n",
        ")"
      ],
      "metadata": {
        "id": "rPxxrchNobEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = TabularPredictor.load(\"drive/My Drive/model/autogluon_1121_train_normal_cycle_96columns_good_noindex_reg_cpu_4h\",require_version_match=False)\n"
      ],
      "metadata": {
        "id": "8bTgwkI2okuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/generated_dataset.csv')\n",
        "score = predictor.predict(test.iloc[0:1])\n",
        "score"
      ],
      "metadata": {
        "id": "FSl5mtTmouY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b96f3f29-dde7-4951-9f87-33e80d99e0c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2.021022\n",
              "Name: fail60, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Ns1qFXF_rQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard(\n",
        "    data_train_12_mean_failure_60_noTimeLable_tab,\n",
        "    silent=True\n",
        ")"
      ],
      "metadata": {
        "id": "Upmq5SXDowvk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}